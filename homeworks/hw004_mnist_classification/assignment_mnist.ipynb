{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework #4\n",
    "\n",
    "##### Author: [Radoslav Neychev](https://www.linkedin.com/in/radoslav-neychev/), @neychev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "import torchvision\n",
    "from torchvision.datasets import MNIST\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task #1: \n",
    "Let's turn to the classic problem of handwritten digit recognition. We will be working with the [MNIST](http://yann.lecun.com/exdb/mnist/) dataset. In this task, we will use the entire dataset as a whole.\n",
    "\n",
    "__Your main task is to implement the entire model training pipeline and achieve an accuracy of $\\geq 92\\%$ on the test set.__\n",
    "\n",
    "The code for training the model is missing in this task. There are only a few tests that will help you debug your solution. For an example, you can refer to the notebook from the first lesson.\n",
    "\n",
    "We strongly recommend writing the code \"from scratch,\" only glancing at ready-made examples, rather than just \"copy-pasting\". This will help you in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n",
      "100.0%\n",
      "100.0%\n",
      "100.0%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Image label: 4')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "\n",
    "train_mnist_data = MNIST('.', train=True, transform=torchvision.transforms.ToTensor(), download=True)\n",
    "test_mnist_data = MNIST('.', train=False, transform=torchvision.transforms.ToTensor(), download=True)\n",
    "\n",
    "\n",
    "train_data_loader = torch.utils.data.DataLoader(\n",
    "    train_mnist_data,\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    num_workers=2\n",
    ")\n",
    "\n",
    "test_data_loader = torch.utils.data.DataLoader(\n",
    "    test_mnist_data,\n",
    "    batch_size=32,\n",
    "    shuffle=False,\n",
    "    num_workers=2\n",
    ")\n",
    "\n",
    "random_batch = next(iter(train_data_loader))\n",
    "_image, _label = random_batch[0][0], random_batch[1][0]\n",
    "plt.figure()\n",
    "plt.imshow(_image.reshape(28, 28))\n",
    "plt.title(f'Image label: {_label}')\n",
    "# __________end of block__________"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the model below. Please do not construct an overly complicated network; it should not be deeper than four layers (it can be less). Your main task is to train the model and achieve at least 92% accuracy on the test set (hold-out set).\n",
    "\n",
    "*Note: Linear layers and activation functions should suffice.*\n",
    "\n",
    "__Keep in mind, your model should be represented by the variable `model`__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating model instance\n",
    "import torch.optim as optim\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.fc1 = nn.Linear(784, 128)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.shape[0], -1) \n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "model = Model()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Local tests for checking your model are available below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Everything seems fine!\n"
     ]
    }
   ],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "assert model is not None, 'Please, use `model` variable to store your model'\n",
    "\n",
    "try:\n",
    "    x = random_batch[0].reshape(-1, 784)\n",
    "    y = random_batch[1]\n",
    "\n",
    "    # compute outputs given inputs, both are variables\n",
    "    y_predicted = model(x)    \n",
    "except Exception as e:\n",
    "    print('Something is wrong with the model')\n",
    "    raise e\n",
    "    \n",
    "    \n",
    "assert y_predicted.shape[-1] == 10, 'Model should predict 10 logits/probas'\n",
    "\n",
    "print('Everything seems fine!')\n",
    "# __________end of block__________"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train your model on the training set. We recommend experimenting with different optimizers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.0404\n",
      "Epoch [2/10], Loss: 0.0318\n",
      "Epoch [3/10], Loss: 0.0253\n",
      "Epoch [4/10], Loss: 0.0201\n",
      "Epoch [5/10], Loss: 0.0166\n",
      "Epoch [6/10], Loss: 0.0147\n",
      "Epoch [7/10], Loss: 0.0122\n",
      "Epoch [8/10], Loss: 0.0109\n",
      "Epoch [9/10], Loss: 0.0082\n",
      "Epoch [10/10], Loss: 0.0077\n",
      "Final Accuracy on Test Set: 97.80%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for i, (images, labels) in enumerate(train_data_loader):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(images)\n",
    "        \n",
    "        loss = criterion(outputs, labels)        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss / len(train_data_loader):.4f}\")\n",
    "\n",
    "model.eval() \n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_data_loader:\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f'Final Accuracy on Test Set: {accuracy:.2f}%')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, remember that you can always refer to the excellent [documentation](https://pytorch.org/docs/stable/index.html) and [tutorials](https://pytorch.org/tutorials/)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's evaluate the classification quality:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = []\n",
    "real_labels = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch in train_data_loader:\n",
    "        y_predicted = model(batch[0].reshape(-1, 784))\n",
    "        predicted_labels.append(y_predicted.argmax(dim=1))\n",
    "        real_labels.append(batch[1])\n",
    "\n",
    "predicted_labels = torch.cat(predicted_labels)\n",
    "real_labels = torch.cat(real_labels)\n",
    "train_acc = (predicted_labels == real_labels).type(torch.FloatTensor).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural network accuracy on train set: 0.98967\n"
     ]
    }
   ],
   "source": [
    "print(f'Neural network accuracy on train set: {train_acc:3.5}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = []\n",
    "real_labels = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch in test_data_loader:\n",
    "        y_predicted = model(batch[0].reshape(-1, 784))\n",
    "        predicted_labels.append(y_predicted.argmax(dim=1))\n",
    "        real_labels.append(batch[1])\n",
    "\n",
    "predicted_labels = torch.cat(predicted_labels)\n",
    "real_labels = torch.cat(real_labels)\n",
    "test_acc = (predicted_labels == real_labels).type(torch.FloatTensor).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural network accuracy on test set: 0.978\n"
     ]
    }
   ],
   "source": [
    "print(f'Neural network accuracy on test set: {test_acc:3.5}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that the necessary thresholds are passed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert test_acc >= 0.92, 'Test accuracy is below 0.92 threshold'\n",
    "assert train_acc >= 0.91, 'Train accuracy is below 0.91 while test accuracy is fine. We recommend to check your model and data flow'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submitting the Assignment\n",
    "Upload the file `hw04_data_dict.npy` (link is below) and run the code below to generate your submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: wget\n"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/girafe-ai/ml-course/blob/26s_harbour/homeworks/hw004_mnist_classification/hw04_data_dict.npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved to `submission_dict_hw04.json`\n"
     ]
    }
   ],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "import os\n",
    "import json\n",
    "assert os.path.exists('hw04_data_dict.npy'), 'Please, download `hw04_data_dict.npy` and place it in the working directory'\n",
    "\n",
    "def get_predictions(model, eval_data, step=10):\n",
    "    \n",
    "    predicted_labels = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for idx in range(0, len(eval_data), step):\n",
    "            y_predicted = model(eval_data[idx:idx+step].reshape(-1, 784))\n",
    "            predicted_labels.append(y_predicted.argmax(dim=1))\n",
    "    \n",
    "    predicted_labels = torch.cat(predicted_labels).numpy()\n",
    "    predicted_labels = ','.join([str(x) for x in list(predicted_labels)])\n",
    "    return predicted_labels\n",
    "\n",
    "loaded_data_dict = np.load('hw04_data_dict.npy', allow_pickle=True)\n",
    "\n",
    "submission_dict = {\n",
    "    'train': get_predictions(model, torch.FloatTensor(loaded_data_dict.item()['train'])),\n",
    "    'test': get_predictions(model, torch.FloatTensor(loaded_data_dict.item()['test']))\n",
    "}\n",
    "\n",
    "with open('submission_dict_hw04.json', 'w') as iofile:\n",
    "    json.dump(submission_dict, iofile)\n",
    "print('File saved to `submission_dict_hw04.json`')\n",
    "# __________end of block__________"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With that, the task is complete. Congratulations!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my-python3-kernel",
   "language": "python",
   "name": "my-python3-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
